{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Google Drive Scraper\n",
        "### Douyin Video Data Extraction/Translation\n",
        "\n",
        "This Google Colab notebook scrapes a Google Drive folder containing Douyin videos, extracts metadata (title, date, duration), translates titles to English, and generates a spreadsheet with hyperlinks to the videos.\n",
        "\n",
        "Here's a breakdown in bullet points:\n",
        "* **Authenticates**: Connects to Google Drive and Google Translate API using service account credentials.\n",
        "* **Traverses Files**: Walks through a specified Google Drive folder containing subfolders for each company and their Douyin videos.\n",
        "* **Extracts Metadata**: Extracts the video title and upload date from the filename.\n",
        "* **Translates**: Translates the video titles (Chinese to English using Google Translate API).\n",
        "* **Calculates Duration**: Calculates the video duration using the moviepy library.\n",
        "* **Generates Links**: Retrieves Google Drive web view links for each video.\n",
        "* **Creates Spreadsheet**: Organizes all extracted data into a Pandas DataFrame and exports it to an Excel file with clickable hyperlinks to the videos."
      ],
      "metadata": {
        "id": "-PMz76eIVhxK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IqkZu80uYoLT",
        "outputId": "16d23099-7515-45ce-d8e4-0a539cc8e55e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-api-python-client pandas ffmpeg-python"
      ],
      "metadata": {
        "id": "ZUJQ8hK-Y4Yc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e2d425b-b360-4999-e14b-4f6aa1e72ac6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (2.151.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Collecting ffmpeg-python\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (0.22.0)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.27.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (0.2.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (2.19.2)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client) (4.1.1)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python) (1.0.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.66.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (4.25.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (1.25.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (4.9)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0.dev0,>=1.32.0->google-api-python-client) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0.dev0,>=1.31.5->google-api-python-client) (2024.8.30)\n",
            "Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Installing collected packages: ffmpeg-python\n",
            "Successfully installed ffmpeg-python-0.2.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hook up to G Drive\n",
        "from google.oauth2 import service_account\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "creds = service_account.Credentials.from_service_account_file('credentials.json')\n",
        "drive_service = build('drive', 'v3', credentials=creds)\n"
      ],
      "metadata": {
        "id": "qbQcpG7LZx2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Folder traversal for ids\n",
        "def find_folder_id(service, folder_name, parent_folder_id):\n",
        "    try:\n",
        "        # Query to search within the specified parent folder\n",
        "        query = (\n",
        "            f\"name = '{folder_name}' and mimeType = 'application/vnd.google-apps.folder'\"\n",
        "            f\" and '{parent_folder_id}' in parents\"\n",
        "        )\n",
        "\n",
        "        # print(f\"Searching for folder: {folder_name} with query: {query}\")\n",
        "        results = service.files().list(q=query, supportsAllDrives=True, includeItemsFromAllDrives=True, fields=\"files(id, name)\").execute()\n",
        "        items = results.get('files', [])\n",
        "\n",
        "        if not items:\n",
        "            print(f\"No folder found with name: {folder_name} in parent ID: {parent_folder_id}\")\n",
        "            return None\n",
        "\n",
        "        # Take the first matching folder\n",
        "        # print(f\"Found folder with ID: {items[0]['id']}\")\n",
        "        return items[0]['id']\n",
        "\n",
        "    except Exception as error:\n",
        "        print(f\"An error occurred: {error}\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "yLmoyqkcMnez"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Q17OTk_W2wqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set helper functions\n",
        "# Function to format seconds as hh:mm:ss\n",
        "def format_duration(seconds):\n",
        "    try:\n",
        "        hours = int(seconds // 3600)\n",
        "        minutes = int((seconds % 3600) // 60)\n",
        "        secs = int(seconds % 60)\n",
        "        return f\"{hours:02}:{minutes:02}:{secs:02}\"\n",
        "    except TypeError:\n",
        "        return \"00:00:00\"  # Default for missing or invalid durations\n",
        "\n",
        "# Function to translate text to English\n",
        "def translate_to_english(text):\n",
        "    try:\n",
        "        result = translate_service.translations().list(\n",
        "            q=text,\n",
        "            target='en'\n",
        "        ).execute()\n",
        "        return result['translations'][0]['translatedText']\n",
        "    except Exception as e:\n",
        "        print(f\"Translation error for '{text}': {e}\")\n",
        "        return text  # Return the original text if translation fails"
      ],
      "metadata": {
        "id": "lL6B3oRjktHd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Constants\n",
        "import os\n",
        "import pandas as pd\n",
        "from moviepy.editor import VideoFileClip\n",
        "from googleapiclient.discovery import build\n",
        "from google.oauth2 import service_account\n",
        "\n",
        "# Authenticate with Google Translate API\n",
        "translate_creds = service_account.Credentials.from_service_account_file('credentials.json')\n",
        "translate_service = build('translate', 'v2', credentials=translate_creds)\n",
        "\n",
        "# Specify the root folder in Google Drive\n",
        "oo_dir_TEST = \"local\"\n",
        "oo_dir_TEST_folderId = \"1jtuO8NuGO3ZCTFIi73MGb3JN3rtkIH6_\"\n",
        "\n",
        "oo_dir_1 = \"Downloaded Douyin videos\"\n",
        "oo_dir_1_folderId = \"11ECto7u2RGXz3tRRPzcaUqv4ovwl7FUt\"\n",
        "\n",
        "oo_dir_2 = \"Downloaded Douyin videos for aquaculture companies\"\n",
        "oo_dir_2_folderId = \"1DJacV51PrVI1MZLX7saYAWIG0a8rIQSr\"\n",
        "\n",
        "oo_dir_3 = \"Downloaded Douyin videos for aquaculture companies/主页作品\"\n",
        "oo_dir_3_folderId = \"14NXizuyC6W1vFGhvt3w2RXYMI7cSuRY-\"\n",
        "\n",
        "oo_dir_4 = \"Downloaded Douyin videos for aquaculture companies/主页作品 (Nov 24)\"\n",
        "oo_dir_4_folderId = \"1VPzJAPzENtF9dOHs03aO2NXw6ysqPB_e\"\n",
        "\n",
        "ROOT = \"/content/drive/MyDrive/outlaw-ocean/\""
      ],
      "metadata": {
        "id": "N3yOz0c9lxkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Build file mapping to webview link\n",
        "def fetch_files_in_folder(folder_id):\n",
        "    \"\"\"Retrieve all file names and IDs in a folder.\"\"\"\n",
        "    files = []\n",
        "    page_token = None\n",
        "    while True:\n",
        "        # print(f\"Fetching files in folder with ID: {folder_id}\")\n",
        "        response = drive_service.files().list(\n",
        "            q=f\"'{folder_id}' in parents\",\n",
        "            fields=\"nextPageToken, files(id, name)\",\n",
        "            supportsAllDrives=True,\n",
        "            includeItemsFromAllDrives=True,  # Includes files from shared drives\n",
        "            pageToken=page_token\n",
        "        ).execute()\n",
        "        files.extend(response.get('files', []))\n",
        "        page_token = response.get('nextPageToken')\n",
        "        if not page_token:\n",
        "            break\n",
        "    # print(f\"Fetched {len(files)} files in total, see: {files}\")\n",
        "    return files\n",
        "\n",
        "def get_file_info(file_id):\n",
        "    \"\"\"Retrieve file metadata using its unique ID.\"\"\"\n",
        "    try:\n",
        "        file = drive_service.files().get(\n",
        "            fileId=file_id,\n",
        "            fields=\"id, name, webViewLink\",\n",
        "            supportsAllDrives=True,\n",
        "        ).execute()\n",
        "        return file\n",
        "    except Exception as e:\n",
        "        print(f\"Error retrieving file info for ID {file_id}: {e}\")\n",
        "        return None\n",
        "\n",
        "def build_name_to_id_map(folder_id):\n",
        "    \"\"\"Build a mapping of file names to IDs for a folder.\"\"\"\n",
        "    files = fetch_files_in_folder(folder_id)\n",
        "    return {file['name']: file['id'] for file in files}"
      ],
      "metadata": {
        "id": "Owv7OKhBclFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Real meat & potatoes\n",
        "# Initialize data list\n",
        "data = []\n",
        "\n",
        "# Starting parameters\n",
        "isTranslate = True\n",
        "isDuration = True\n",
        "isExcel = True\n",
        "root_folder = ROOT + oo_dir_4\n",
        "\n",
        "# Map local dirpath to Drive folder IDs (manual or through API)\n",
        "dirpath_to_drive_id = {\n",
        "    ROOT + oo_dir_TEST : oo_dir_TEST_folderId,\n",
        "    ROOT + oo_dir_1 : oo_dir_1_folderId,\n",
        "    ROOT + oo_dir_2 : oo_dir_2_folderId,\n",
        "    ROOT + oo_dir_3 : oo_dir_3_folderId,\n",
        "    ROOT + oo_dir_4 : oo_dir_4_folderId\n",
        "}\n",
        "\n",
        "# Traverse files\n",
        "MAX_FILES = 6600;\n",
        "num_files = 0;\n",
        "num_dirs = 0\n",
        "parent_folder = dirpath_to_drive_id.get(root_folder)\n",
        "for dirpath, dirnames, filenames in os.walk(root_folder):\n",
        "    print(f\"Processing directory: {dirpath}\")\n",
        "    if num_files > MAX_FILES:\n",
        "        break\n",
        "\n",
        "    company = os.path.basename(dirpath)  # Folder name as company\n",
        "\n",
        "    # Get the folder ID for this directory\n",
        "    folder_id = find_folder_id(drive_service, company, parent_folder)\n",
        "\n",
        "    # Build file -> webview link mapping\n",
        "    if not folder_id:\n",
        "        print(f\"Folder not found for company: {company}\")\n",
        "        folder_id = parent_folder\n",
        "        continue\n",
        "\n",
        "    num_dirs += 1\n",
        "    name_to_id_map = build_name_to_id_map(folder_id)\n",
        "\n",
        "    # Convert company name to English\n",
        "    translated_company = translate_to_english(company) if isTranslate else company\n",
        "\n",
        "    for file in filenames:\n",
        "        if file.endswith(('.mp4', '.mov', '.avi')):  # Add more extensions if needed\n",
        "            num_files += 1\n",
        "            if num_files > MAX_FILES:\n",
        "                break\n",
        "            filepath = os.path.join(dirpath, file)\n",
        "\n",
        "            # Extract title: Match between the '-' and the '.mp4'\n",
        "            title = file[file.find('-') + 1:file.rfind('.mp4')].strip()\n",
        "\n",
        "            date = file.split('-')[0]  # Extract date before dash\n",
        "\n",
        "            # Translate the title to English\n",
        "            translated_title = translate_to_english(title) if isTranslate else title\n",
        "\n",
        "            # Get hyperlink for the file\n",
        "            file_id = name_to_id_map.get(file)\n",
        "            if not file_id:\n",
        "                print(f\"File ID not found for file: {file}\")\n",
        "                 # Try looser key examination\n",
        "                for key in name_to_id_map.keys():\n",
        "                    if key[:15] == file[:15]:  # Compare the first 15 characters\n",
        "                        file_id = name_to_id_map[key]\n",
        "                        print(f\"Looser match found: {file_id} for key: {key}\")\n",
        "                        break\n",
        "                if (file_id == None):\n",
        "                    print(f\"No matching file ID found for file: {file}\")\n",
        "                    hyperlink = \"\"\n",
        "            else :\n",
        "                file_info = get_file_info(file_id)\n",
        "                hyperlink = file_info['webViewLink'] if file_info else \"\"\n",
        "\n",
        "            # Calculate video duration and format as hh:mm:ss\n",
        "            try:\n",
        "                if isDuration:\n",
        "                    clip = VideoFileClip(filepath, audio=False)\n",
        "                    duration_seconds = clip.duration\n",
        "                    duration_formatted = format_duration(duration_seconds)\n",
        "                    clip.close()\n",
        "                else:\n",
        "                    duration_formatted = \"00:00:00\"\n",
        "            except Exception as e:\n",
        "                duration_formatted = \"00:00:00\"  # Default for errors\n",
        "\n",
        "            # Append the extracted data\n",
        "            data.append({\n",
        "                \"Company\": company,\n",
        "                \"Translated Company\" : translated_company,\n",
        "                \"Date\": date,\n",
        "                \"Hyperlink\": hyperlink if hyperlink else \"\",\n",
        "                \"Title\": title,\n",
        "                \"Translated Title\": translated_title,\n",
        "                \"Duration\": duration_formatted\n",
        "            })\n",
        "    print(f\"Completed {num_dirs} directories\")\n",
        "\n",
        "# Create a DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Convert to hyperlinks\n",
        "if (isExcel):\n",
        "  df['Hyperlink'] = df['Hyperlink'].apply(lambda url: f'=HYPERLINK(\"{url}\", \"link\")' if url else \"\")\n",
        "  # df['Hyperlink'] = df['Hyperlink'].apply(lambda url: url if url else \"\")\n",
        "  df.to_excel('/content/video_index_with_hyperlinks_主页作品 (Nov 24).xlsx', index=False)\n",
        "else :\n",
        "  # Save to a CSV file\n",
        "  df.to_csv('/content/video_index_with_translation.csv', index=False)\n",
        "\n",
        "print(\"Complete!\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ur49p23_cZFW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}